{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# WeightMapper Interactive Demo\n",
    "\n",
    "This notebook demonstrates the capabilities of the `WeightMapper` class for mapping weights between different model architectures.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `WeightMapper` helps transfer learned weights from one model architecture to another, even when layer names have changed. This is useful for:\n",
    "\n",
    "- Model refactoring\n",
    "- Architecture migrations\n",
    "- Transfer learning with renamed layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from lit_wsl.models.weight_mapper import WeightMapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Part 1: Basic Weight Mapping Between Models\n",
    "\n",
    "Let's start by defining two similar models with different naming conventions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple source model\n",
    "class OldModel(nn.Module):\n",
    "    \"\"\"Original model architecture.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 8 * 8, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.backbone(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a target model with similar but renamed structure\n",
    "class NewModel(nn.Module):\n",
    "    \"\"\"New model architecture with renamed layers.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(128 * 8 * 8, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Test 1: Basic Weight Mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "old_model = OldModel()\n",
    "new_model = NewModel()\n",
    "\n",
    "# Create mapper\n",
    "mapper = WeightMapper(old_model, new_model)\n",
    "\n",
    "# Generate mapping\n",
    "mapping = mapper.suggest_mapping(threshold=0.5)\n",
    "\n",
    "# Print analysis\n",
    "print(\"Weight Mapping Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "mapper.print_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated mapping\n",
    "print(\"\\nGenerated Mapping Dictionary:\")\n",
    "print(\"=\" * 80)\n",
    "for source, target in mapping.items():\n",
    "    print(f\"{source} -> {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Test 2: Conservative Mapping Strategy\n",
    "\n",
    "The conservative strategy uses a higher threshold for more confident matches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_conservative = WeightMapper(old_model, new_model)\n",
    "mapping_conservative = mapper_conservative.suggest_mapping(threshold=0.7, strategy=\"conservative\")\n",
    "\n",
    "print(f\"Conservative mapping found {len(mapping_conservative)} matches\")\n",
    "print(\"Mapping:\")\n",
    "for source, target in mapping_conservative.items():\n",
    "    print(f\"  {source} -> {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Test 3: Shape-Only Mapping Strategy\n",
    "\n",
    "This strategy only considers parameter shapes, ignoring names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_shape = WeightMapper(old_model, new_model)\n",
    "mapping_shape = mapper_shape.suggest_mapping(strategy=\"shape_only\")\n",
    "\n",
    "print(f\"Shape-only mapping found {len(mapping_shape)} matches\")\n",
    "print(\"\\nFirst 5 mappings:\")\n",
    "for source, target in list(mapping_shape.items())[:5]:\n",
    "    source_shape = mapper_shape.source_params[source].shape\n",
    "    print(f\"{source} ({source_shape}) -> {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Test 4: Mapping with Confidence Scores\n",
    "\n",
    "View mappings sorted by confidence scores to identify the most reliable matches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_scores = WeightMapper(old_model, new_model)\n",
    "mapper_scores.suggest_mapping()\n",
    "\n",
    "# Get mappings with scores\n",
    "mappings_with_scores = mapper_scores.get_mapping_with_scores()\n",
    "\n",
    "# Sort by score\n",
    "mappings_with_scores.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"Top 10 mappings by confidence score:\")\n",
    "print(f\"{'Source':<40} {'Target':<40} {'Score':>8}\")\n",
    "print(\"-\" * 90)\n",
    "for source, target, score in mappings_with_scores[:10]:\n",
    "    print(f\"{source:<40} {target:<40} {score:>7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Test 5: Export Mapping Report\n",
    "\n",
    "Export the mapping analysis to a JSON file for future reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_export = WeightMapper(old_model, new_model)\n",
    "mapper_export.suggest_mapping()\n",
    "\n",
    "# Export report\n",
    "output_path = \"/tmp/weight_mapping_report.json\"\n",
    "mapper_export.export_mapping_report(output_path)\n",
    "\n",
    "print(f\"Report exported successfully to {output_path}\")\n",
    "\n",
    "# Display the report content\n",
    "import json\n",
    "\n",
    "with open(output_path) as f:\n",
    "    report = json.load(f)\n",
    "    print(\"\\nReport summary:\")\n",
    "    print(f\"  Total mappings: {len(report.get('mapping', {}))}\")\n",
    "    print(f\"  Unmapped source params: {len(report.get('unmapped_source', []))}\")\n",
    "    print(f\"  Unmapped target params: {len(report.get('unmapped_target', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Part 2: Mapping from State Dict\n",
    "\n",
    "This section demonstrates how to use `WeightMapper` when you only have a checkpoint file (state dict) without access to the original model code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models for state dict demo\n",
    "class OldModelV2(nn.Module):\n",
    "    \"\"\"Original model architecture.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(64 * 32 * 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "\n",
    "class NewModelV2(nn.Module):\n",
    "    \"\"\"Refactored model architecture.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 32 * 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Step 1: Create and Save Old Model Checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate having an old checkpoint\n",
    "print(\"Creating old model and saving checkpoint...\")\n",
    "old_model_v2 = OldModelV2()\n",
    "checkpoint_path = \"/tmp/old_model_checkpoint.pth\"\n",
    "\n",
    "# Save as a typical PyTorch checkpoint\n",
    "torch.save(\n",
    "    {\n",
    "        \"state_dict\": old_model_v2.state_dict(),\n",
    "        \"epoch\": 42,\n",
    "        \"optimizer_state\": {},  # Would normally have optimizer state\n",
    "    },\n",
    "    checkpoint_path,\n",
    ")\n",
    "print(f\"✓ Saved checkpoint to {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Step 2: Load Checkpoint Without Original Model Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now pretend we don't have access to OldModelV2 class anymore\n",
    "from lit_wsl.models.checkpoint import load_checkpoint_as_dict\n",
    "\n",
    "print(\"Loading checkpoint (without old model code)...\")\n",
    "checkpoint = load_checkpoint_as_dict(checkpoint_path)\n",
    "old_weights = checkpoint[\"state_dict\"]\n",
    "\n",
    "print(f\"✓ Loaded {len(old_weights)} parameters from checkpoint\")\n",
    "print(f\"  Sample keys: {list(old_weights.keys())[:3]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Step 3: Create New Model and Mapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model\n",
    "print(\"Creating new model architecture...\")\n",
    "new_model_v2 = NewModelV2()\n",
    "print(f\"✓ New model has {len(list(new_model_v2.parameters()))} parameters\")\n",
    "print(f\"  Sample keys: {list(new_model_v2.state_dict().keys())[:3]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapper from state dict\n",
    "print(\"Creating WeightMapper from state dict...\")\n",
    "mapper_from_dict = WeightMapper.from_state_dict(old_weights, new_model_v2)\n",
    "print(\"✓ Mapper created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Step 4: Generate and Analyze Mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mapping\n",
    "print(\"Generating weight mapping...\")\n",
    "mapping_dict = mapper_from_dict.suggest_mapping(strategy=\"best_match\", threshold=0.5)\n",
    "print(f\"✓ Found {len(mapping_dict)} parameter mappings\")\n",
    "\n",
    "# Show analysis\n",
    "print(\"\\nMapping analysis:\")\n",
    "print(\"-\" * 80)\n",
    "mapper_from_dict.print_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Step 5: Apply Mapping and Load Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mapping to checkpoint\n",
    "print(\"Applying mapping to create new checkpoint...\")\n",
    "new_weights = {}\n",
    "for old_key, new_key in mapping_dict.items():\n",
    "    new_weights[new_key] = old_weights[old_key]\n",
    "\n",
    "# Load into new model\n",
    "missing, unexpected = new_model_v2.load_state_dict(new_weights, strict=False)\n",
    "print(f\"✓ Loaded {len(new_weights)} weights into new model\")\n",
    "\n",
    "if missing:\n",
    "    print(f\"  Missing keys: {len(missing)}\")\n",
    "    print(f\"  Examples: {list(missing)[:3]}\")\n",
    "if unexpected:\n",
    "    print(f\"  Unexpected keys: {len(unexpected)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ Successfully mapped weights from old checkpoint to new model!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary files\n",
    "import os\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    os.remove(checkpoint_path)\n",
    "    print(f\"Cleaned up {checkpoint_path}\")\n",
    "\n",
    "if os.path.exists(\"/tmp/weight_mapping_report.json\"):\n",
    "    os.remove(\"/tmp/weight_mapping_report.json\")\n",
    "    print(\"Cleaned up /tmp/weight_mapping_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Basic weight mapping** between two models with different naming conventions\n",
    "2. **Different mapping strategies**: conservative, shape-only, and best-match\n",
    "3. **Confidence scores** for evaluating mapping quality\n",
    "4. **Export capabilities** for saving mapping reports\n",
    "5. **State dict mapping** for working with checkpoints when original model code is unavailable\n",
    "\n",
    "The `WeightMapper` class provides flexible and powerful tools for transferring weights between different model architectures, making it easier to refactor code while preserving learned parameters.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
